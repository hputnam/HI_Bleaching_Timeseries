url8 = "WATERLEVEL_6MIN_VFD_PX.F," #return quality flag
url9 = "WATERLEVEL_6MIN_VFD_PX.R," #return quality flag
url10 = "WATERLEVEL_6MIN_VFD_PX.T" #return quality flag
#The remaining parts of the url specify how to filter the data on the server
#to only retrieve the desired station and date range. Values must be enclosed
#in ascii double-quotes, which are represented by the code %22
url11 = "&WATERLEVEL_6MIN_VFD_PX._STATION_ID=%22" #station gets added here
url12 = "%22"
url13 = "&WATERLEVEL_6MIN_VFD_PX._DATUM=%22MSL%22"#we want MLLW as the datum
url14 = "&WATERLEVEL_6MIN_VFD_PX._BEGIN_DATE=%22" #start date gets added here
url15 = "%22"
url16 = "&WATERLEVEL_6MIN_VFD_PX._END_DATE=%22" #end date gets added here
url17 = "%22"
##### DON'T CHANGE ANY CODE ABOVE THIS LINE ###########
########################################################################
urltotal = paste(url1,url2,url3,url4,url5,url6,url7,url8,url9,url10,url11,
station,url12,url13,url14,startdate,url15,url16,enddate,url17,sep ="")
cat("Contacting server...\n"); flush.console()
dat = getURL(urltotal) #use RCurl to retrieve text into a vector 'dat'
cat("Data returned...\n"); flush.console()
Sys.sleep(2) #pause for a few seconds to avoid overloading server
#cleanup
rm(url1,url2,url3,url4,url5,url6,url7,url8,url9,url10,url11,url12,url13,url14)
rm(url15,url16,url17)
con = textConnection(dat) #create text Connection to dat vector
all.lines = readLines(con) #read lines of text into separate slots in a vector
close(con) #close connection to dat vector
if (length(grep('^Error',all.lines))>0) { #check for error in retrieval
cat("There was an error...\n")
cat(dat,"\n") #print contents of dat to show error
flush.console()
} else {
#The column headers are typically preceded by a line of dashes
headerlines = grep("^--------",all.lines) #find index of headers (-1)
#read column header names into a vector
con = textConnection(dat)
headers = scan(con, skip = headerlines, nlines = 1, sep = ",",
what = "character", strip.white = TRUE)
close(con)
#read rest of the data into a data frame 'df'
con = textConnection(dat)
df = read.table(con, skip = headerlines+1, sep = ",", header = FALSE,
quote = "\"", col.names = headers, strip.white = TRUE,
stringsAsFactors = FALSE)
close(con)
###########################################################################
#The following operations will need to be altered if you change the
#fields or data type being returned by the OPeNDAP server
#Convert the time column to POSIX time (seconds since 1970-01-01 00:00:00)
df[,3] = as.POSIXct(strptime(df[,3],format = "%b %d %Y %I:%M%p",
tz = "GMT"))
#Give the columns shorter names
names(df) = c("stationId","datum","TimeUTC","TideHT","Flag.Inferred",
"Flag.Flat.Tol","Flag.Rate.Tol","Flag.Temp.Tol")
#Uncomment this if you want to plot the data
#plot(df$TimeUTC, df$TideHT, type = "l",
#		xlab = "Date",ylab = "Tide Height, meters")
#Save data automatically to a .csv file.
filename = paste("Station_",station,"_tide_ht_",startdate,"-",enddate,
".csv",sep = "")
write.csv(df,filename,row.names = FALSE, quote = FALSE)
cat("Saved to ",filename,"\n")
flush.console()
#Alternate file save method lets user specify file name at run time
#write.csv(df,file.choose(),row.names = FALSE, quote = FALSE)
#cleanup
rm(dat,con,all.lines,startdate,enddate,filename,headerlines, headers,df,
urltotal)
} #end of if-else statement
} #end of mo for-loop
################################################################################
## ENTER YOUR STATION ID AND YEARS HERE ##
station = 1612480 #Enter your desired station ID here
year = 2019  #Enter the first year of data to get here
year2 = 2019 #Enter the last year of data to get here (can be same as 1st year)
for (yr in year:year2) {
leap = leap.year(yr) #test if desired year is a leap year
for (mo in 7:11) { #start of mo for-loop
#create text string for month value
if (mo < 7) {month = paste("0",as.character(mo),sep="")} else {
month = as.character(mo)
}
#figure out number of days in month
if ((mo == 4) | (mo == 6) | (mo == 9) | (mo == 11)) {nday = 30} else {
if (mo == 2 & leap == TRUE) {nday = 29} else {
if (mo == 2 & leap == FALSE) {nday = 28} else nday = 31 }
}
startdate = paste(yr,month,"01",sep = "")
enddate = paste(yr,month,nday,sep = "")
#OPeNDAP query for 6-minute verified water level looks like this (on 1 line):
#http://opendap.co-ops.nos.noaa.gov/dods/IOOS/
#SixMin_Verified_Water_Level.ascii?
#WATERLEVEL_6MIN_VFD_PX._STATION_ID,
#WATERLEVEL_6MIN_VFD_PX._DATUM,
#WATERLEVEL_6MIN_VFD_PX.DATE_TIME,
#WATERLEVEL_6MIN_VFD_PX.WL_VALUE,
#WATERLEVEL_6MIN_VFD_PX.I,
#WATERLEVEL_6MIN_VFD_PX.F,
#WATERLEVEL_6MIN_VFD_PX.R,
#WATERLEVEL_6MIN_VFD_PX.T
#&WATERLEVEL_6MIN_VFD_PX._STATION_ID=%229449880%22
#&WATERLEVEL_6MIN_VFD_PX._DATUM=%22MLLW%22
#&WATERLEVEL_6MIN_VFD_PX._BEGIN_DATE=%2220080801%22
#&WATERLEVEL_6MIN_VFD_PX._END_DATE=%2220080808%22
########################################################
###### DON'T CHANGE ANY OF THE CODE BELOW THIS LINE ####
#The parts of the url
url1 = "http://opendap.co-ops.nos.noaa.gov/dods/IOOS/"
url2 = "SixMin_Verified_Water_Level.ascii?"
url3 = "WATERLEVEL_6MIN_VFD_PX._STATION_ID," #return stationId
url4 = "WATERLEVEL_6MIN_VFD_PX._DATUM," #return datum
url5 = "WATERLEVEL_6MIN_VFD_PX.DATE_TIME," #return record date-time
url6 = "WATERLEVEL_6MIN_VFD_PX.WL_VALUE," #return water level value
url7 = "WATERLEVEL_6MIN_VFD_PX.I," #return quality flag
url8 = "WATERLEVEL_6MIN_VFD_PX.F," #return quality flag
url9 = "WATERLEVEL_6MIN_VFD_PX.R," #return quality flag
url10 = "WATERLEVEL_6MIN_VFD_PX.T" #return quality flag
#The remaining parts of the url specify how to filter the data on the server
#to only retrieve the desired station and date range. Values must be enclosed
#in ascii double-quotes, which are represented by the code %22
url11 = "&WATERLEVEL_6MIN_VFD_PX._STATION_ID=%22" #station gets added here
url12 = "%22"
url13 = "&WATERLEVEL_6MIN_VFD_PX._DATUM=%22MSL%22"#we want MLLW as the datum
url14 = "&WATERLEVEL_6MIN_VFD_PX._BEGIN_DATE=%22" #start date gets added here
url15 = "%22"
url16 = "&WATERLEVEL_6MIN_VFD_PX._END_DATE=%22" #end date gets added here
url17 = "%22"
##### DON'T CHANGE ANY CODE ABOVE THIS LINE ###########
########################################################################
urltotal = paste(url1,url2,url3,url4,url5,url6,url7,url8,url9,url10,url11,
station,url12,url13,url14,startdate,url15,url16,enddate,url17,sep ="")
cat("Contacting server...\n"); flush.console()
dat = getURL(urltotal) #use RCurl to retrieve text into a vector 'dat'
cat("Data returned...\n"); flush.console()
Sys.sleep(2) #pause for a few seconds to avoid overloading server
#cleanup
rm(url1,url2,url3,url4,url5,url6,url7,url8,url9,url10,url11,url12,url13,url14)
rm(url15,url16,url17)
con = textConnection(dat) #create text Connection to dat vector
all.lines = readLines(con) #read lines of text into separate slots in a vector
close(con) #close connection to dat vector
if (length(grep('^Error',all.lines))>0) { #check for error in retrieval
cat("There was an error...\n")
cat(dat,"\n") #print contents of dat to show error
flush.console()
} else {
#The column headers are typically preceded by a line of dashes
headerlines = grep("^--------",all.lines) #find index of headers (-1)
#read column header names into a vector
con = textConnection(dat)
headers = scan(con, skip = headerlines, nlines = 1, sep = ",",
what = "character", strip.white = TRUE)
close(con)
#read rest of the data into a data frame 'df'
con = textConnection(dat)
df = read.table(con, skip = headerlines+1, sep = ",", header = FALSE,
quote = "\"", col.names = headers, strip.white = TRUE,
stringsAsFactors = FALSE)
close(con)
###########################################################################
#The following operations will need to be altered if you change the
#fields or data type being returned by the OPeNDAP server
#Convert the time column to POSIX time (seconds since 1970-01-01 00:00:00)
df[,3] = as.POSIXct(strptime(df[,3],format = "%b %d %Y %I:%M%p",
tz = "GMT"))
#Give the columns shorter names
names(df) = c("stationId","datum","TimeUTC","TideHT","Flag.Inferred",
"Flag.Flat.Tol","Flag.Rate.Tol","Flag.Temp.Tol")
#Uncomment this if you want to plot the data
#plot(df$TimeUTC, df$TideHT, type = "l",
#		xlab = "Date",ylab = "Tide Height, meters")
#Save data automatically to a .csv file.
filename = paste("Station_",station,"_tide_ht_",startdate,"-",enddate,
".csv",sep = "")
write.csv(df,filename,row.names = FALSE, quote = FALSE)
cat("Saved to ",filename,"\n")
flush.console()
#Alternate file save method lets user specify file name at run time
#write.csv(df,file.choose(),row.names = FALSE, quote = FALSE)
#cleanup
rm(dat,con,all.lines,startdate,enddate,filename,headerlines, headers,df,
urltotal)
} #end of if-else statement
} #end of mo for-loop
} #end of yr for-loop
install.packages("rnoaa")
library(rnoaa)
ersst(year = 2019, month = 10)
ersst(year = 2019, month = "10")
ersst(year = "2019", month = "10")
###############################################################################
require(RCurl) #If you don't have this, type install.packages("RCurl") at the
#R command line before running this script.
require(chron) #for the leap.year function
################################################################################
## ENTER YOUR STATION ID AND YEARS HERE ##
station = 1612480 #Enter your desired station ID here
year = 2019  #Enter the first year of data to get here
year2 = 2019 #Enter the last year of data to get here (can be same as 1st year)
for (yr in year:year2) {
leap = leap.year(yr) #test if desired year is a leap year
for (mo in 7:11) { #start of mo for-loop
#create text string for month value
if (mo < 7) {month = paste("0",as.character(mo),sep="")} else {
month = as.character(mo)
}
#figure out number of days in month
if ((mo == 9) | (mo == 11)) {nday = 30} else {
if (mo == 2 & leap == TRUE) {nday = 29} else {
if (mo == 2 & leap == FALSE) {nday = 28} else nday = 31 }
}
startdate = paste(yr,month,"01",sep = "")
enddate = paste(yr,month,nday,sep = "")
#OPeNDAP query for 6-minute verified water TEMP looks like this (on 1 line):
#http://opendap.co-ops.nos.noaa.gov/dods/IOOS/
#SixMin_Verified_Water_TEMP.ascii?
#WATERTEMP_6MIN_VFD_PX._STATION_ID,
#WATERTEMP_6MIN_VFD_PX._DATUM,
#WATERTEMP_6MIN_VFD_PX.DATE_TIME,
#WATERTEMP_6MIN_VFD_PX.WL_VALUE,
#WATERTEMP_6MIN_VFD_PX.I,
#WATERTEMP_6MIN_VFD_PX.F,
#WATERTEMP_6MIN_VFD_PX.R,
#WATERTEMP_6MIN_VFD_PX.T
#&WATERTEMP_6MIN_VFD_PX._STATION_ID=%229449880%22
#&WATERTEMP_6MIN_VFD_PX._DATUM=%22MLLW%22
#&WATERTEMP_6MIN_VFD_PX._BEGIN_DATE=%2220080801%22
#&WATERTEMP_6MIN_VFD_PX._END_DATE=%2220080808%22
########################################################
###### DON'T CHANGE ANY OF THE CODE BELOW THIS LINE ####
#The parts of the url
url1 = "http://opendap.co-ops.nos.noaa.gov/dods/IOOS/"
url2 = "SixMin_Verified_Water_TEMP.ascii?"
url3 = "WATERTEMP_6MIN_VFD_PX._STATION_ID," #return stationId
url4 = "WATERTEMP_6MIN_VFD_PX._DATUM," #return datum
url5 = "WATERTEMP_6MIN_VFD_PX.DATE_TIME," #return record date-time
url6 = "WATERTEMP_6MIN_VFD_PX.WL_VALUE," #return water TEMP value
url7 = "WATERTEMP_6MIN_VFD_PX.I," #return quality flag
url8 = "WATERTEMP_6MIN_VFD_PX.F," #return quality flag
url9 = "WATERTEMP_6MIN_VFD_PX.R," #return quality flag
url10 = "WATERTEMP_6MIN_VFD_PX.T" #return quality flag
#The remaining parts of the url specify how to filter the data on the server
#to only retrieve the desired station and date range. Values must be enclosed
#in ascii double-quotes, which are represented by the code %22
url11 = "&WATERTEMP_6MIN_VFD_PX._STATION_ID=%22" #station gets added here
url12 = "%22"
url13 = "&WATERTEMP_6MIN_VFD_PX._DATUM=%22MSL%22"#we want MLLW as the datum
url14 = "&WATERTEMP_6MIN_VFD_PX._BEGIN_DATE=%22" #start date gets added here
url15 = "%22"
url16 = "&WATERTEMP_6MIN_VFD_PX._END_DATE=%22" #end date gets added here
url17 = "%22"
##### DON'T CHANGE ANY CODE ABOVE THIS LINE ###########
########################################################################
urltotal = paste(url1,url2,url3,url4,url5,url6,url7,url8,url9,url10,url11,
station,url12,url13,url14,startdate,url15,url16,enddate,url17,sep ="")
cat("Contacting server...\n"); flush.console()
dat = getURL(urltotal) #use RCurl to retrieve text into a vector 'dat'
cat("Data returned...\n"); flush.console()
Sys.sleep(2) #pause for a few seconds to avoid overloading server
#cleanup
rm(url1,url2,url3,url4,url5,url6,url7,url8,url9,url10,url11,url12,url13,url14)
rm(url15,url16,url17)
con = textConnection(dat) #create text Connection to dat vector
all.lines = readLines(con) #read lines of text into separate slots in a vector
close(con) #close connection to dat vector
if (length(grep('^Error',all.lines))>0) { #check for error in retrieval
cat("There was an error...\n")
cat(dat,"\n") #print contents of dat to show error
flush.console()
} else {
#The column headers are typically preceded by a line of dashes
headerlines = grep("^--------",all.lines) #find index of headers (-1)
#read column header names into a vector
con = textConnection(dat)
headers = scan(con, skip = headerlines, nlines = 1, sep = ",",
what = "character", strip.white = TRUE)
close(con)
#read rest of the data into a data frame 'df'
con = textConnection(dat)
df = read.table(con, skip = headerlines+1, sep = ",", header = FALSE,
quote = "\"", col.names = headers, strip.white = TRUE,
stringsAsFactors = FALSE)
close(con)
###########################################################################
#The following operations will need to be altered if you change the
#fields or data type being returned by the OPeNDAP server
#Convert the time column to POSIX time (seconds since 1970-01-01 00:00:00)
df[,3] = as.POSIXct(strptime(df[,3],format = "%b %d %Y %I:%M%p",
tz = "GMT"))
#Give the columns shorter names
names(df) = c("stationId","datum","TimeUTC","TideHT","Flag.Inferred",
"Flag.Flat.Tol","Flag.Rate.Tol","Flag.Temp.Tol")
#Uncomment this if you want to plot the data
#plot(df$TimeUTC, df$TideHT, type = "l",
#		xlab = "Date",ylab = "Tide Height, meters")
#Save data automatically to a .csv file.
filename = paste("Station_",station,"_tide_ht_",startdate,"-",enddate,
".csv",sep = "")
write.csv(df,filename,row.names = FALSE, quote = FALSE)
cat("Saved to ",filename,"\n")
flush.console()
#Alternate file save method lets user specify file name at run time
#write.csv(df,file.choose(),row.names = FALSE, quote = FALSE)
#cleanup
rm(dat,con,all.lines,startdate,enddate,filename,headerlines, headers,df,
urltotal)
} #end of if-else statement
} #end of mo for-loop
} #end of yr for-loop
group1_products <- c(           # sub-hourly products with 31 day max
"water_level",  "air_temperature",  "water_temperature",
"wind", "air_pressure", "air_gap", "conductivity",
"visibility", "humidity", "salinity", "one_minute_water_level",
"predictions", "currents")
group1_products <- c("water_level",  "air_temperature",  "water_temperature","wind", "air_pressure",
"air_gap", "conductivity", "visibility", "humidity", "salinity",
"one_minute_water_level", "predictions", "currents")
group1_products
if (product %in% group1_products) {
maxdur <- 31
}
group1_products <- c(           # sub-hourly products with 31 day max
"water_level",  "air_temperature",  "water_temperature",
"wind", "air_pressure", "air_gap", "conductivity",
"visibility", "humidity", "salinity", "one_minute_water_level",
"predictions", "currents")
group2_products <- c(   # hourly to sub-daily products with 1 year max
"hourly_height", "high_low")
group3_products <- c(      # daily or longer products with 10 year max
"daily_mean", "monthly_mean")
if (product %in% group1_products) {
maxdur <- 31
} else if (product %in% group2_products) {
maxdur <- 366
} else if (product %in% group3_products) {
maxdur <- 3653
} else maxdur <- 365000
water_level_products <- c(
"water_level", "hourly_height", "high_low",
"daily_mean", "monthly_mean", "one_minute_water_level", "predictions")
library(rnoaa)
coops_search <- function(begin_date = 2019-07-01, end_date = 2019-10-13, station_name = mokuoloe,
product, datum = NULL, units = "metric", time_zone = "gmt",
application = "rnoaa")
library(rnoaa)
noaa_datasets(stationid = 1612480)
ncdc_datasets(stationid = 1612480)
stations <- noaa_stations(locationid = "ZIP:96744")
ncdc_stations <- ncdc_stations(locationid = "ZIP:96744")
setwd("~/Documents/Professional/GitHub/HI_Bleaching_Timeseries")
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
# load packages
library(vegan)
library(tidyverse)
library(reshape2)
# Clear environment
rm(list = ls())
# Set seed
set.seed(54321)
# Import data
Master <- read.csv("data/PhysData.csv")
Master$ColonyID <- as.factor(Master$ColonyID)
Master$Date <- as.Date(Master$Date, format = "%m/%d/%y")
Master$group <- paste(Master$Species, Master$Bleach, Master$Date) # Add group name for species, date and phenotype
Master$spe.bl <- paste(Master$Species, Master$Bleach) # Add group name for species and phenotype
Master$spe.da <- paste(Master$Species, Master$Date) # Add group name for species and date
# Subset for timeseries and response variables
mcap <- na.omit(subset(Master, Date >= "2019-09-16" & Date <= "2019-10-30" & Species == "Montipora capitata")[,c("ColonyID","Bleach","Date","Species","spe.bl","spe.da", "group", "Yield", "BleachScore", "BM.mgcm2", "R.umolcm2hr", "GP.umolcm2hr", "SymSA.cellcm2","ChlSA.ugcm2", "TACProt.uMug", "ProtSA.mgcm2")])
mcap$identifier <- rownames(mcap)
# Scale and center data
mcapscaled <- scale(mcap[8:16], center = T, scale = T)
# Identify Factors
fac.mcap <- mcap[1:7]
# PCA
pca.out.mcap <- prcomp(mcapscaled, center=FALSE, scale=FALSE)
summary(pca.out.mcap)
biplot(pca.out.mcap)
PC1 <- pca.out.mcap$x[,1]
PC2 <- pca.out.mcap$x[,2]
# PERMANOVA
mod.mcap <- adonis2(mcapscaled ~ Bleach * Date, data = mcap, method = "euclidian") # PERMANOVA
mod.mcap
vec.mcap <- envfit(pca.out.mcap, mcap[8:16], perm = 1000) #fit physiological vectors onto ordination
vecdf.mcap <- as.data.frame(vec.mcap$vectors$arrows * sqrt(vec.mcap$vectors$r))
vecdf.mcap$variable <- rownames(vecdf.mcap)
# Gather info for plotting
pca.df.mcap <- data.frame(pca.out.mcap$x[,1], y = pca.out.mcap$x[,2],
Colony = as.factor(fac.mcap$ColonyID),
Bleach = as.factor(fac.mcap$Bleach),
Date = as.factor(fac.mcap$Date),
Species = as.factor(fac.mcap$Species),
spe.bl = as.factor(fac.mcap$spe.bl),
spe.da = as.factor(fac.mcap$spe.da),
group = as.factor(fac.mcap$group))
# Order levels
pca.df.mcap$Bleach <- factor(pca.df.mcap$spe.bl, levels = c("Montipora capitata Bleach", "Montipora capitata Non-bleach"))
pca.df.mcap$Date <- factor(pca.df.mcap$spe.da, levels = c("Montipora capitata 2019-09-16", "Montipora capitata 2019-10-02", "Montipora capitata 2019-10-16", "Montipora capitata 2019-10-30"))
pca.df.mcap$group <- factor(pca.df.mcap$group, levels = c("Montipora capitata Bleach 2019-09-16", "Montipora capitata Non-bleach 2019-09-16", "Montipora capitata Bleach 2019-10-02", "Montipora capitata Non-bleach 2019-10-02",
"Montipora capitata Bleach 2019-10-16", "Montipora capitata Non-bleach 2019-10-16", "Montipora capitata Bleach 2019-10-30", "Montipora capitata Non-bleach 2019-10-30"))
# Set column names
colnames(pca.df.mcap)[1:2] <- c("PC1", "PC2")
# Subset for timeseries and response variables
pcom <- na.omit(subset(Master, Date >= "2019-09-16" & Date <= "2019-10-30" & Species == "Porites compressa")[,c("ColonyID","Bleach","Date","Species","spe.bl","spe.da", "group", "Yield", "BleachScore", "BM.mgcm2", "R.umolcm2hr", "GP.umolcm2hr", "SymSA.cellcm2","ChlSA.ugcm2", "TACProt.uMug", "ProtSA.mgcm2")])
pcom$identifier <- rownames(pcom)
# Scale and center data
pcomscaled <- scale(pcom[8:16], center = T, scale = T)
# Identify Factors
fac.pcom <- pcom[1:7]
# PCA
pca.out.pcom <- prcomp(pcomscaled, center=FALSE, scale=FALSE)
summary(pca.out.pcom)
biplot(pca.out.pcom)
PC1 <- pca.out.pcom$x[,1]
PC2 <- pca.out.pcom$x[,2]
# PERMANOVA
mod.pcom <- adonis2(pcomscaled ~ Bleach * Date, data = pcom, method = "euclidian") # PERMANOVA
mod.pcom
vec.pcom <- envfit(pca.out.pcom, pcom[8:16], perm = 1000) #fit physiological vectors onto ordination
vecdf.pcom <- as.data.frame(vec.pcom$vectors$arrows * sqrt(vec.pcom$vectors$r))
vecdf.pcom$variable <- rownames(vecdf.pcom)
# Gather info for plotting
pca.df.pcom <- data.frame(pca.out.pcom$x[,1], y = pca.out.pcom$x[,2],
Colony = as.factor(fac.pcom$ColonyID),
Bleach = as.factor(fac.pcom$Bleach),
Date = as.factor(fac.pcom$Date),
Species = as.factor(fac.pcom$Species),
spe.bl = as.factor(fac.pcom$spe.bl),
spe.da = as.factor(fac.pcom$spe.da),
group = as.factor(fac.pcom$group))
# Order levels
pca.df.pcom$Bleach <- factor(pca.df.pcom$spe.bl, levels = c("Porites compressa Bleach", "Porites compressa Non-bleach"))
pca.df.pcom$Date <- factor(pca.df.pcom$spe.da, levels = c("Porites compressa 2019-09-16", "Porites compressa 2019-10-02", "Porites compressa 2019-10-16", "Porites compressa 2019-10-30"))
pca.df.pcom$group <- factor(pca.df.pcom$group, levels = c("Porites compressa Bleach 2019-09-16", "Porites compressa Non-bleach 2019-09-16", "Porites compressa Bleach 2019-10-02", "Porites compressa Non-bleach 2019-10-02",
"Porites compressa Bleach 2019-10-16", "Porites compressa Non-bleach 2019-10-16", "Porites compressa Bleach 2019-10-30", "Porites compressa Non-bleach 2019-10-30"))
# Set column names
colnames(pca.df.pcom)[1:2] <- c("PC1", "PC2")
# Set colors - p,b,1; p,nb,1; p,b,2...
bleachcolors <- c("red", "blue")
date.symbols <- c(3, 5, 15, 16)
par(mfrow=c(1,2))
PCA.M.plot <- ordiplot(pca.out.mcap, type = "n", display = "sites", ylim=c(-5,5), xlim=c(-5,5), xlab=c("PC1 (31%)"), ylab=c("PC2 (20%)"))
points(PCA.M.plot, "sites", col = bleachcolors[pca.df.mcap$Bleach], cex=0.8, pch=date.symbols[pca.df.mcap$Date])
par.new = T
plot(vec.mcap, col = "black", cex = 0.5)
title(main = "MCAP")
PCA.P.plot <- ordiplot(pca.out.pcom, type = "n", display = "sites", ylim=c(-5,5), xlim=c(-5,5), xlab=c("PC1 (29%)"), ylab=c("PC2 (18%)"))
points(PCA.P.plot, "sites", col = bleachcolors[pca.df.pcom$Bleach], cex=0.8, pch=date.symbols[pca.df.pcom$Date])
par.new = T
plot(vec.pcom, col = "black", cex = 0.5)
title(main = "PCOM")
View(Master)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# load packages
library(lme4)
library(ggplot2)
library(MuMIn)
library(car)
library(lmerTest)
library(emmeans)
library(multcomp)
library(lattice)
library(effects)
library(sjPlot)
Master <- subset(Master, Date < "2020-02-01")
View(Master)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# load packages
library(lme4)
library(ggplot2)
library(MuMIn)
library(car)
library(lmerTest)
library(emmeans)
library(multcomp)
library(lattice)
library(effects)
library(sjPlot)
rm(list = ls())
Master <- read.csv("data/PhysData.csv")
setwd("~/Documents/Professional/GitHub/HI_Bleaching_Timeseries")
rm(list = ls())
Master <- read.csv("data/PhysData.csv")
Master$ColonyID <- as.factor(Master$ColonyID)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# load packages
library(lme4)
library(ggplot2)
library(MuMIn)
library(car)
library(lmerTest)
library(emmeans)
library(multcomp)
library(lattice)
library(effects)
library(sjPlot)
rm(list = ls())
Master <- read.csv("data/PhysData.csv")
Master <- read.csv("data/PhysData.csv")
setwd("~/Documents/Professional/GitHub/HI_Bleaching_Timeseries")
Master <- read.csv("data/PhysData.csv")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# load packages
library(vegan)
library(tidyverse)
library(reshape2)
# Clear environment
rm(list = ls())
# Set seed
set.seed(54321)
# Import data
Master <- read.csv("data/PhysData.csv")
